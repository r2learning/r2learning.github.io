---
layout: default
title: Relational Representation Learning
---

## <a name="overview"></a> Overview

**Date and Time:** 8:45 AM - 6:00 PM, December 8, 2018  
**Location:** Room 517A, Palais des Congrès de Montréal, Montréal, Canada

Relational reasoning, *i.e.*, learning and inference with relational data, is key to understanding how objects interact with each other and give rise to complex phenomena in the everyday world. Well-known applications include knowledge base completion and social network analysis. Although many relational datasets are available, integrating them directly into modern machine learning algorithms and systems that rely on continuous, gradient-based optimization and make strong i.i.d. assumptions is challenging. Relational representation learning has the potential to overcome these obstacles: it enables the fusion of recent advancements like deep learning and relational reasoning to learn from high-dimensional data. Success of such methods can facilitate novel applications of relational reasoning in areas such as scene understanding, visual question-answering, understanding chemical and biological processes, program synthesis and analysis, decision-making in multi-agent systems and many others.

How should we rethink classical representation learning theory for relational representations? Classical approaches based on dimensionality reduction techniques such as isoMap and spectral decompositions still serve as strong baselines and are slowly paving the way for modern methods in relational representation learning based on random walks over graphs, message-passing in neural networks, group-invariant deep architectures etc. amongst many others. How can systems be designed and potentially deployed for large scale representation learning? What are promising avenues, beyond traditional applications like knowledge base and social network analysis, that can benefit from relational representation learning?

This workshop aims to bring together researchers from both academia and industry interested in addressing various aspects of representation learning for relational reasoning. 

## <a name="speakers"></a> Invited Speakers
[Joan Bruna](https://cims.nyu.edu/~bruna/), New York University    
[Pedro Domingos](https://homes.cs.washington.edu/~pedrod/), University of Washington   
[Lise Getoor](https://getoor.soe.ucsc.edu/home), University of California, Santa Cruz   
[Timothy Lillicrap](http://contrastiveconvergence.net/~timothylillicrap/index.php), Google Deepmind     
[Marina Meila](https://www.stat.washington.edu/mmp/), University of Washington   
[Maximilian Nickel](https://mnick.github.io/), Facebook Artificial Intelligence Research     

## <a name="schedule"></a> Schedule

| **Time**  | **Event**|
|-----------------------------------------------|-----------------------------------------------------------------------------------|
|8:45-9:00 AM &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  |  Welcome  |
|9:00-9:30 AM  |  **Invited Talk:** Marina Meila  |
|9:30-9:45 AM  | **Contributed Talk:** Charlotte Bunne <br/> *Learning Generative Models across Incomparable Spaces*  |
|9:45-10:30 AM | **Invited Talk:**  Maximilian Nickel   |
|10:15-10:30 AM| **Poster Spotlights Talks** |
|10:30-11:00 AM| Coffee Break + Poster Session 1  |
|11:00-11:15 AM| **Contributed Talk:** Lingfei Wu <br/> *From Node Embedding to Graph Embedding: Scalable Global Graph Kernel via Random Features*|
|11:15-11:45 AM| **Invited Talk:**  Timothy Lillicrap   |
|11:45-12:00 PM| **Contributed Talk:** Yunsheng Bai <br/> *Convolutional Set Matching for Graph Similarity*|
|12:00-2:00 PM | Lunch |
|2:00-2:30 PM  | **Invited Talk:** Lise Getoor|
|2:30-2:45 PM  | **Contributed Talk:** Robert Csordas <br/> *Improved addressing in the Differentiable Neural Computer*|
|2:45-3:00 PM  | **Poster Spotlight Talks**|
|3:00-3:30 PM  | Coffee Break + Poster Session 2|
|3:30-4:00 PM  | **Invited Talk:**  Joan Bruna|
|4:00-4:30 PM  | **Invited Talk:**  Pedro Domingos| 
|4:30-5:00 PM  | **Panel** <br/> Moderator: Paroma Varma <br/> Panelists: Aditya Grover, William Hamilton, Jessica Hamrick, Thomas Kipf, Marinka Zitnik|
|5:15-5:30 PM  | Closing Remarks|
|5:30-6:30 PM  | Poster Session|

<!-- ## <a name="submission"></a> Call for Papers
### Paper Submission Instructions
Workshop papers should be at most **4 pages of content**, including text and figures. Additional pages containing only bibliographic references can be included without penalty. 

We welcome and encourage position papers on this subject. We are also particularly interested in papers that introduce datasets and competitions to further progress in the field.

### Submission Guidelines
Workshop papers should be at most **4 pages of content**, including text and figures, excluding references. Authors can include an appendix of supplementary material after the references. However, reviewers will not be required to consult any appendices to make their decisions. The main 4-page paper should adequately describe the work and its contributions.

Papers should be anonymized and adhere to the NeurIPS conference format: [https://neurips.cc/Conferences/2018/PaperInformation/StyleFiles](https://neurips.cc/Conferences/2018/PaperInformation/StyleFiles)

**Submission Site:** [https://cmt3.research.microsoft.com/R2L2018](https://cmt3.research.microsoft.com/R2L2018)

### Peer Review and Acceptance Criteria
All submissions will go through a double-blind peer review process. Accepted papers will be chosen based on techincal merit, interest, and novelty. The workshop allows submissions of papers that are under review or have been recently published in a conference or a journal. Authors should state any overlapping published work at the time of submission.

All accepted papers will be included in one of the two poster presentation and lightning talk sessions on the day of the workshop. Some accepted papers will be invited to give contributed oral talks. Final versions of accepted papers will be posted on the workshop website. These are archival but do not constitute a proceedings and can be submitted elsewhere.

All accepted papers will be included in one of the two poster presentation and lightning talk sessions on the day of the workshop. Some accepted papers will be invited to give a contributed oral talks.  -->

### Important Dates 
* **Submission Deadline: October 19th, 2018, 23:59 PST**
* Notification of Acceptance: November 2nd, 2018
* Camera-ready Due: November 16th, 2018
* Workshop: December 8, 2018
* Contact: r2learning@googlegroups.com

## <a name="organizers"></a> Organizers 
[Aditya Grover](http://aditya-grover.github.io/), Stanford University  
[Paroma Varma](https://paroma.github.io/), Stanford University   
[Fred Sala](https://stanford.edu/~fredsala/), Stanford University  
[Steven Holtzen](https://web.cs.ucla.edu/~sholtzen/), University of California, Los Angeles  
[Jennifer Neville](https://www.cs.purdue.edu/homes/neville/index.html), Purdue University  
[Stefano Ermon](https://cs.stanford.edu/~ermon/), Stanford University  
[Christopher Ré](https://cs.stanford.edu/people/chrismre/), Stanford University

## <a name="papers"></a> Accepted Papers 
* [On the Complexity of Exploration in Goal-driven Navigation](assets/papers/hippo-r2l-camera-ready.pdf). Maruan Al-Shedivat, Lisa Lee, Ruslan Salakhutdinov, Eric Xing 
* Improving Knowledge Graph Embeddings with Inferred Entity Types. Esma Balkir, Masha Naslidnyk, Dave Palfrey, Arpit Mittal 
* [Deep Graph Infomax](http://petar-v.com/dgi_nips18_camera.pdf). Petar Veličković, Liam Fedus, William Hamilton, Pietro Liò, Yoshua Bengio, Devon Hjelm 
* [Image-Level Attentional Context Modeling Using Nested-Graph Neural Networks](https://arxiv.org/pdf/1811.03830.pdf). Guillaume Jaume, Behzad Bozorgtabar, Hazim Kemal Ekenel, Jean-Philippe Thiran, Maria Gabrani 
* [Compositional Language Understanding with Text-based Relational Reasoning](assets/papers/CameraReadySubmission 8.pdf). Koustuv Sinha, Shagun Sodhani, William L Hamilton, Joelle Pineau 
* [Learning Graph Representation via Formal Concept Analysis](http://www.ar.sanken.osaka-u.ac.jp/pub/yoneda/NIPSWS2018_cr1113.pdf). Yuka Yoneda, Mahito Sugiyama, Takashi Washio 
* [A Simple Baseline Algorithm for Graph Classification](https://arxiv.org/pdf/1810.09155.pdf). Nathan De Lara, Edouard Pineau 
* [Pitfalls of Graph Neural Network Evaluation](https://arxiv.org/pdf/1811.05868.pdf). Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, Stephan Günnemann 
* [TNE: A Latent Model for Representation Learning on Networks](https://abdcelikkanat.github.io/projects/TNE/TNE_R2L2018.pdf). Abdulkadir Celikkanat, Fragkiskos Malliaros 
* Using Ternary Rewards to Reason over Knowledge Graphs with Deep Reinforcement Learning. Frederic Godin, Anjishnu Kumar, Arpit Mittal 
* [A Case for Object Compositionality in GANs](https://drive.google.com/open?id=1HtZqg5mFXm3xeM-8Q8O1DlAd-2apGaik). Sjoerd van Steenkiste, Karol Kurach, Sylvain Gelly 
* [Learning DPPs by Sampling Inferred Negatives](https://zelda.lids.mit.edu/wp-content/uploads/sites/17/2018/11/nips_workshop.pdf). Zelda Mariet, Mike Gartrell, Suvrit Sra 
* [LanczosNet: Multi-Scale Deep Graph Convolutional Networks](http://www.cs.toronto.edu/~rjliao/assets/papers/NIPS_R2L_lanczos_net.pdf). Renjie Liao, Zhizhen Zhao, Raquel Urtasun, Richard Zemel 
* [Chess2vec: Learning Vector Representations for Chess](http://www.berkkapicioglu.com/wp-content/uploads/2018/11/chess2vec_nips_2018_short.pdf). Berk Kapicioglu, Ramiz Iqbal 
* [Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models](http://wushanshan.github.io/files/GraphicalModel_workshop.pdf). Shanshan Wu, Sujay Sanghavi, Alex Dimakis 
* [Towards Sparse Hierarchical Graph Classifiers](http://petar-v.com/spcls_nips18_camera.pdf). Catalina Cangea, Petar Veličković, Nikola Jovanović, Thomas Kipf, Pietro Liò 
* [GRevnet: Improving Graph Neural Nets with Reversible Computation](https://drive.google.com/file/d/1UYsTSnyKjl6MAox9vwGtV77wB_3vMavR/view?usp=sharing ). Aviral Kumar, Jimmy Ba, Jamie Kiros, Kevin Swersky 
* [Detecting the Coarse Geometry of Networks](https://www.mis.mpg.de/preprints/2018/preprint2018_97.pdf). Melanie Weber, Emil Saucan, Jürgen Jost 
* [Modeling Attention Flow on Graphs](https://xiaoranxu.com/files/attflow_short_Xu.pdf). Xiaoran Xu 
* [Learning Generative Models across Incomparable Spaces](https://polybox.ethz.ch/index.php/s/rZ53hhP9pyUor56). Charlotte Bunne, Stefanie Jegelka, David Alvarez-Melis, Andreas Krause 
* [Hierarchical Bipartite Graph Convolution Networks](https://drive.google.com/file/d/1cJabrT7Y_HN2DTuIkJz7kWiAFIlz9OOt/view?usp=sharing). Marcel Nassar 
* [Non-local RoI for Cross-Object Perception](https://drive.google.com/open?id=1idZrhvIL8n2rGWyz2x3fLOByrqeSsRz5). Shou-Yao Tseng, Hwann-Tzong Chen, Shao-Heng Tai, Tyng-Luh Liu 
* [Node Attribute Prediction: An Evaluation of Within- versus Across-Network Tasks](http://stanford.edu/~jugander/assets/papers/nips18w-withinacross.pdf). Kristen M. Altenburger, Johan Ugander 
* Implicit Maximum Likelihood Estimation. Ke Li, Jitendra Malik 
* [Variational learning across domains with triplet information](https://arxiv.org/pdf/1806.08672.pdf). Rita Kuznetsova 
* Fast k-Nearest Neighbour Search via Prioritized DCI. Ke Li, Jitendra Malik 
* [Deep Determinantal Point Processes](https://arxiv.org/pdf/1811.07245.pdf). Mike Gartrell, Elvis Dohmatob 
* [Higher-Order Graph Convolutional Layer](http://sami.haija.org/assets/papers/high-order-gc-layer.pdf). Sami A Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Hrayr Harutyunyan 
* [Convolutional Set Matching for Graph Similarity](http://yunshengb.com/wp-content/uploads/2018/11/Convolutional_Set_Matching_for_Graph_Similarity.pdf). Yunsheng Bai, Hao Ding, Yizhou Sun, Wei Wang 
* [Improving Generalization for Abstract Reasoning Tasks Using Disentangled Feature Representations](https://arxiv.org/pdf/1811.04784.pdf). Xander Steenbrugge, Tim Verbelen, Bart Dhoedt, Sam Leroux 
* [From Node Embedding to Graph Embedding: Scalable Global Graph Kernel via Random Features](assets/papers/RGE_NIPS18_RRL_Workshop.pdf). Lingfei Wu, Ian En-Hsu Yen, Kun Xu, Liang Zhao, Yinglong Xia, Michael Witbrock
* [A Neural Framework for Learning DAG to DAG Translation](http://www.ccs.neu.edu/home/clara/resources/neural-framework-learning.pdf). M. Clara De Paolis Kaluza, Saeed Amizadeh, Rose Yu
* [Semi-supervised learning for clusterable graph embeddings with NMF](https://priyeshv.github.io/R2L_SSNMF.pdf). Priyesh Vijayan, Anasua Mitra, Srinivasan Parthasarathy, Balaraman Ravindran 
* [Lifted Inference for Faster Training in end-to-end neural-CRF models](http://www.cse.iitd.ac.in/~mausam/assets/papers/nipswork18.pdf). Yatin Nandwani, Ankit Anand, Mausam , Parag Singla 
* [Link Prediction in Dynamic Graphs for Recommendation](https://www.ic.unicamp.br/~ra188964/assets/papers/Link_Prediction_in_Dynamic_Graphs_for_Recommendation.pdf). Samuel G. Fadel, Ricardo Torres 
* Curvature and Representation Learning: Identifying Embedding Spaces for Relational Data. Maximillian Nickel 
* [Multi-Task Graph Autoencoders](https://arxiv.org/pdf/1811.02798.pdf). Phi Vu Tran 
* [Personalized Neural Embeddings for Collaborative Filtering with Text](assets/papers/CameraReadySubmission 2.pdf). Guangneng Hu, Yu Zhang 
* [Symbolic Relation Networks for Reinforcement Learning](assets/papers/CameraReadySubmission 3.pdf). Dhaval D Adjodah, Tim Klinger, Josh Joseph 
* [Extending the Capacity of CVAE for Face Sythesis and Modeling](assets/papers/CameraReadySubmission 11.pdf). Shengju Qian, Wayne Wu, Yangxiaokang Liu, Beier Zhu, Fumin Shen 
* [SARN: Relational Reasoning through Sequential Attention](assets/papers/CameraReadySubmission 49.pdf). Jinwon An, Seongwon Lyu, Sungzoon Cho 
* [Pairwise Relational Networks using Local Appearance Features for Face Recognition](https://arxiv.org/pdf/1811.06405.pdf). Bong-Nam Kang, YongHyun Kim, Daijin Kim 
* [Compositional Fairness Constraints for Graph Embeddings](assets/papers/CameraReadySubmission 35.pdf). Avishek Bose, William L Hamilton 
* [Improved Addressing in the Differentiable Neural Computer](http://people.idsia.ch/~csordas/nips2018.pdf). Róbert Csordás, Jürgen Schmidhuber 
* [Efficient Unsupervised Word Sense Induction, Disambiguation and Embedding](https://bigdata1.research.cs.dal.ca/behrouz/publication/nipsw2018/NIPSW2018_EfficientWordSenseDisambiguation.pdf). Behrouz Haji Soleimani, Habibeh Naderi, Stan Matwin 
* [Importance of object selection in Relational Reasoning tasks](assets/papers/CameraReadySubmission 19.pdf). Kshitij Dwivedi, Gemma Roig 
* [On Robust Learning of Ising Models](http://erikml.com/on_robust_learning_of_ising_models.pdf). Erik Lindgren, Vatsal Shah, Yanyao Shen, Alex Dimakis, Adam Klivans 
* [Feed-Forward Neural Networks need Inductive Bias to Learn Equality Relations](assets/papers/CameraReadySubmission 53.pdf). Tillman Weyde, Radha Manisha Kopparti 
* [Tensor Random Projection for Low Memory Dimension Reduction](assets/papers/CameraReadySubmission 41.pdf). Yang Guo, Yiming Sun, Madeleine Udell, Joel Tropp 
* [Leveraging Representation and Inference through Deep Relational Learning](assets/papers/CameraReadySubmission 42.pdf). Maria Leonor Pacheco, Ibrahim Dalal, Dan Goldwasser 
* [Learning Embeddings for Approximate Lifted Inference in MLNs](assets/papers/CameraReadySubmission 48.pdf). Maminur Islam, Somdeb Sarkhel, Deepak Venugopal 
* [Quantum Machine Learning on Knowledge Graphs](assets/papers/CameraReadySubmission 39.pdf). Yunpu Ma, Volker Tresp 

## Program Committee

* Albert Gu, Stanford University
* Alexander Gaunt, Microsoft Research
* Alexander Ratner, Stanford University
* Avner May, Stanford University
* Beliz Gunel, Stanford University
* Bryan He, Stanford University
* Bryan Perozzi, Stonybrook University
* Changping Meng, Purdue University
* Daniel Levy, Stanford University
* Daniel Kang, Stanford University
* Golnoosh Farnadi, UC Santa Cruz
* Guilherme Gomes, Purdue University
* Happy Mittal, IIT Delhi
* Hima Lakkaraju, Harvard University
* Jared Dunnmon, Stanford University
* Jiaming Song, Stanford University
* Jian Zhang, Stanford University
* Jiasen Yang, Purdue University
* Jiaxuan You, Stanford University
* Kristy Choi, Stanford University
* Marinka Zitnik, Stanford University
* Maruan Al-Shedivat, CMU
* Max Lam, Stanford University
* Megan Leszczynski, Stanford University
* Mengyue Hang, Purdue University
* Nikolaos Vasiloglou, RelationalAI
* Oleksandr Polozov, Microsoft Research
* Rex Ying, Stanford University
* Sen Wu, Stanford University
* Tal Friedman, UCLA
* Thomas Kipf, University of Amsterdam
* Tony Ginart, Stanford University
* Tri Dao, Stanford University
* William Hamilton, McGill
* Yang Song, Stanford University
* Yitao Liang, UCLA
* Yujia Li, DeepMind
* Zhaobin Kuang, Stanford University